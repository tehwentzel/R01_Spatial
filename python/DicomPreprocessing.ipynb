{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba80fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5cf8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca637e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import  glob\n",
    "from scipy.spatial import ConvexHull\n",
    "from Constants import Const\n",
    "import joblib\n",
    "from pointcloud_utils import *\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "import matplotlib as mpl\n",
    "import torchio as tio\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from pointcloud_utils import *\n",
    "%matplotlib notebook\n",
    "\n",
    "# from ReaderWriter import BetterDicomReader, dicom_reader_from_ids\n",
    "#from multiprocessing import cpu_count\n",
    "# import typing\n",
    "import os\n",
    "# from queue import *\n",
    "# from tqdm import tqdm\n",
    "# from threading import Thread\n",
    "import pickle\n",
    "import simplejson\n",
    "# import open3d as o3d\n",
    "import pydicom\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f01a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pydicom\n",
    "# import os\n",
    "# files = glob.glob('../data/DICOMs/R01/**/**/**')\n",
    "# dicoms = []\n",
    "# for f in files:\n",
    "#     p = pydicom.dcmread(f)\n",
    "#     if p and not f.endswith('.dcm'):\n",
    "#         newfile = f + '.dcm'\n",
    "#         test = os.rename(f,newfile)\n",
    "#         print(test,f,newfile)\n",
    "#         print('_______')\n",
    "# glob.glob('../data/DICOMs/R01/**/**/**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848ed026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_finished_pids(root=None):\n",
    "    if root is None:\n",
    "        root = Const.pointcloud_dir\n",
    "    files = glob.glob(root + 'pclouds_*.json')\n",
    "    pids = []\n",
    "    for file in files:\n",
    "        pid = file.replace( root+'pclouds_','').replace('.json','')\n",
    "        if pid.isnumeric():\n",
    "            pids.append(int(pid))\n",
    "        else:\n",
    "            print('bad pid',pid)\n",
    "    return pids\n",
    "\n",
    "len(get_finished_pids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25708f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1054079696,\n",
       " 1072572079,\n",
       " 1079757401,\n",
       " 1087308891,\n",
       " 1099927508,\n",
       " 1103015749,\n",
       " 1107681010,\n",
       " 1108642427,\n",
       " 1138096463,\n",
       " 1143391354,\n",
       " 1164546699,\n",
       " 1167168001,\n",
       " 1173728658,\n",
       " 1178044145,\n",
       " 1194116893,\n",
       " 1235569621,\n",
       " 1265845118,\n",
       " 1269213210,\n",
       " 1276736352,\n",
       " 2774318802,\n",
       " 2776638846,\n",
       " 2803120404,\n",
       " 2804890849,\n",
       " 2815583275,\n",
       " 2817169157,\n",
       " 2843895295,\n",
       " 2865890865,\n",
       " 2867468906,\n",
       " 2875588687,\n",
       " 2883823678,\n",
       " 2889102751,\n",
       " 2894996073,\n",
       " 2908060983,\n",
       " 2929571068,\n",
       " 2932807221,\n",
       " 2939740989,\n",
       " 2983776095,\n",
       " 2989874876,\n",
       " 3028333367,\n",
       " 3035721150,\n",
       " 3045110595,\n",
       " 3045556976,\n",
       " 3045918834,\n",
       " 3049758970,\n",
       " 3071491330,\n",
       " 3077525807,\n",
       " 3081060090,\n",
       " 3099145083,\n",
       " 3100266114,\n",
       " 3108161676,\n",
       " 3125978990,\n",
       " 3151449158,\n",
       " 3192749693,\n",
       " 3192926363,\n",
       " 3194171650,\n",
       " 3196236080,\n",
       " 3205005928,\n",
       " 3225956079,\n",
       " 3235750820,\n",
       " 3239454379,\n",
       " 3256350141,\n",
       " 3283538700,\n",
       " 3316448321,\n",
       " 3321571409,\n",
       " 3327830751,\n",
       " 3346286228,\n",
       " 3355839884,\n",
       " 3366888610,\n",
       " 3370207907,\n",
       " 3383739521,\n",
       " 3442548822,\n",
       " 3514335131,\n",
       " 3563849182,\n",
       " 3694073920,\n",
       " 3816960111,\n",
       " 3832820671,\n",
       " 4017119917,\n",
       " 4074385931,\n",
       " 4100593439,\n",
       " 4151569401,\n",
       " 4443664553,\n",
       " 4481544782,\n",
       " 4488837609,\n",
       " 4509480776,\n",
       " 4554821349,\n",
       " 4625578503,\n",
       " 4646292867,\n",
       " 4663235737,\n",
       " 4713240632,\n",
       " 4840069687,\n",
       " 4862586001,\n",
       " 4862920237,\n",
       " 5038138708,\n",
       " 5089502522,\n",
       " 5110518099,\n",
       " 1293745646,\n",
       " 1522246751,\n",
       " 1670301878,\n",
       " 1848656363,\n",
       " 2106963643,\n",
       " 2279280705,\n",
       " 2508553230,\n",
       " 2770898143,\n",
       " 3023016905,\n",
       " 3217148733,\n",
       " 3962148532,\n",
       " 5211387293,\n",
       " 7291736302,\n",
       " 5367270807,\n",
       " 5618650917,\n",
       " 5709953389,\n",
       " 5751912329,\n",
       " 5778599178,\n",
       " 5802597125,\n",
       " 5826154886,\n",
       " 5968002865,\n",
       " 6060411302,\n",
       " 6321133829,\n",
       " 6345257124,\n",
       " 6431977113,\n",
       " 6460317590,\n",
       " 6621233113,\n",
       " 6845023185,\n",
       " 7093179577,\n",
       " 7133027468,\n",
       " 7143413136,\n",
       " 7148485426,\n",
       " 7429045053,\n",
       " 7442321115,\n",
       " 7464252782,\n",
       " 7534086728,\n",
       " 7649615624,\n",
       " 7758510017,\n",
       " 7964193341,\n",
       " 7971396253,\n",
       " 8117442451,\n",
       " 8187553551,\n",
       " 8609286814,\n",
       " 8754332928,\n",
       " 8761936548,\n",
       " 8813226732,\n",
       " 8996674200,\n",
       " 8999014515,\n",
       " 9034884056,\n",
       " 9057869631,\n",
       " 9102331716,\n",
       " 9103199111,\n",
       " 9156619185,\n",
       " 9209984317,\n",
       " 9218314668,\n",
       " 9312513183,\n",
       " 9399080429,\n",
       " 9479197119,\n",
       " 9626079921,\n",
       " 9643148771,\n",
       " 9878102359,\n",
       " 9920271364,\n",
       " 1306278550,\n",
       " 1334966362,\n",
       " 1337145443,\n",
       " 1344996406,\n",
       " 1357557675,\n",
       " 1362035218,\n",
       " 1391235973,\n",
       " 1394607128,\n",
       " 1397224459,\n",
       " 1401915784,\n",
       " 1406457912,\n",
       " 1408814779,\n",
       " 1410220807,\n",
       " 1455535872,\n",
       " 1479250225,\n",
       " 1483470869,\n",
       " 1501485310,\n",
       " 1501555895,\n",
       " 1502711865,\n",
       " 1522266707,\n",
       " 1532016505,\n",
       " 1542701482,\n",
       " 1563200955,\n",
       " 1573361627,\n",
       " 1575888593,\n",
       " 1588865686,\n",
       " 1590784721,\n",
       " 1596568859,\n",
       " 1599623001,\n",
       " 1607489944,\n",
       " 1609087799,\n",
       " 1611205257,\n",
       " 1623384116,\n",
       " 1640653163,\n",
       " 1646439698,\n",
       " 1658195008,\n",
       " 1666942008,\n",
       " 1668489975,\n",
       " 1670863696,\n",
       " 1681729379,\n",
       " 1683645407,\n",
       " 1702727338,\n",
       " 1703830194,\n",
       " 1712166564,\n",
       " 1713967904,\n",
       " 1742118289,\n",
       " 1743819545,\n",
       " 1747497762,\n",
       " 1751828128,\n",
       " 1753932420,\n",
       " 1758588673,\n",
       " 1759548686,\n",
       " 1762684826,\n",
       " 1797332871,\n",
       " 1816775745,\n",
       " 1842859313,\n",
       " 1848265510,\n",
       " 1868407032,\n",
       " 1900858747,\n",
       " 1909580684,\n",
       " 1911652778,\n",
       " 1931216474,\n",
       " 1942951411,\n",
       " 1956723933,\n",
       " 1979650123,\n",
       " 1996203819,\n",
       " 2002304413,\n",
       " 2019523932,\n",
       " 2037015898,\n",
       " 2048566904,\n",
       " 2051712928,\n",
       " 2056532905,\n",
       " 2058768572,\n",
       " 2082761957,\n",
       " 2094315393,\n",
       " 2098577973,\n",
       " 2111490509,\n",
       " 2113254052,\n",
       " 2121257573,\n",
       " 2127966673,\n",
       " 2132983074,\n",
       " 2138657290,\n",
       " 2143352446,\n",
       " 2172401637,\n",
       " 2185606006,\n",
       " 2205986844,\n",
       " 2207447299,\n",
       " 2242981431,\n",
       " 2256221790,\n",
       " 2259228562,\n",
       " 2269261955,\n",
       " 2272549398,\n",
       " 2273533075,\n",
       " 2274749125,\n",
       " 2278293118,\n",
       " 2282925626,\n",
       " 2301668335,\n",
       " 2304398819,\n",
       " 2330992447,\n",
       " 2340030369,\n",
       " 2349637758,\n",
       " 2353613752,\n",
       " 2357210108,\n",
       " 2358616721,\n",
       " 2391362467,\n",
       " 2394091614,\n",
       " 2395750561,\n",
       " 2402957569,\n",
       " 2411034155,\n",
       " 2414841499,\n",
       " 2426779986,\n",
       " 2434097875,\n",
       " 2453598097,\n",
       " 2473779950,\n",
       " 2521737806,\n",
       " 2526692125,\n",
       " 2530084611,\n",
       " 2547923440,\n",
       " 2582708397,\n",
       " 2584370324,\n",
       " 2590278837,\n",
       " 2592917372,\n",
       " 2606564123,\n",
       " 2614564390,\n",
       " 2621609894,\n",
       " 2627209674,\n",
       " 2630686320,\n",
       " 2632834590,\n",
       " 2633689500,\n",
       " 2666617610,\n",
       " 2677877484,\n",
       " 2683892776,\n",
       " 2692140912,\n",
       " 2699434663,\n",
       " 2701548670,\n",
       " 2716829242,\n",
       " 2719881586,\n",
       " 2724951078,\n",
       " 2733957858,\n",
       " 2749596965,\n",
       " 2752224580,\n",
       " 2765835024,\n",
       " 2767317435]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_dicom_ids(root = None):\n",
    "    if root is None:\n",
    "        root = Const.unprocessed_dicoms\n",
    "    files = glob.glob(root+'*/')\n",
    "    ids = []\n",
    "    for f  in files:\n",
    "        pid = f.replace(root,'').replace('/','')\n",
    "        if pid.isnumeric():\n",
    "            ids.append(int(pid))\n",
    "        else:\n",
    "            print('bad pid',pid)\n",
    "    return ids\n",
    "get_all_dicom_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171a49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_folder(root,pid,as_dict=True):\n",
    "    files = glob.glob(root+str(pid) + '/**/**')\n",
    "    entry = {}\n",
    "    pids = set([])\n",
    "    pid2 = False\n",
    "    for f in files:\n",
    "        p = pydicom.dcmread(f)\n",
    "        pid2 = str(p.PatientName)\n",
    "        pids.add(pid2)\n",
    "        dtype = str(p.SOPClassUID.name)\n",
    "        subentry = entry.get(dtype,[])\n",
    "        subentry.append(p)\n",
    "        entry[dtype] = subentry\n",
    "    if len(pids) > 1:\n",
    "        print('mutilple ids',pids)\n",
    "    if as_dict:\n",
    "        return {int(pid2): entry}\n",
    "    return entry, pid2\n",
    "\n",
    "def sample_pids(sample_size=10,skip_finished=True):\n",
    "    potential_ids = get_all_dicom_ids()\n",
    "    if skip_finished:\n",
    "        to_skip = get_finished_pids()\n",
    "        potential_ids = [pid for pid in potential_ids if pid not in to_skip]\n",
    "    if sample_size is not None and sample_size < len(potential_ids):\n",
    "        potential_ids = potential_ids[:sample_size]\n",
    "    return potential_ids\n",
    "\n",
    "def load_dicoms(skip_finished=True,sample_size=10):\n",
    "    root = Const.unprocessed_dicoms\n",
    "    to_skip = []\n",
    "    potential_ids = sample_pids(sample_size=sample_size,skip_finished=skip_finished)\n",
    "    dicom_files = {}\n",
    "    files = []\n",
    "    for pid in potential_ids:\n",
    "        pentry,new_pid = load_patient_folder(root,pid,as_dict=False)\n",
    "        if str(new_pid) != str(pid):\n",
    "            print('id mismatch',pid,new_pid)\n",
    "        dicom_files[int(new_pid)] = pentry\n",
    "\n",
    "    return dicom_files\n",
    "\n",
    "def load_dicoms_by_ids(pids):\n",
    "    dicom_files = {}\n",
    "    for pid in pids:\n",
    "        pentry, newpid = load_patient_folder(Const.unprocessed_dicoms,pid,as_dict=False)\n",
    "        if str(newpid) != str(pid):\n",
    "            print('id mismatch',pid,newpid)\n",
    "        dicom_files[int(newpid)] = pentry\n",
    "    return dicom_files\n",
    "\n",
    "# load_dicoms_by_ids([4646292867, 9643148771])\n",
    "# dicom_files = load_dicoms(sample_size=30)\n",
    "# dicom_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08787208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(ds,string,default=False):\n",
    "    try:\n",
    "        return ds.data_element(string).value\n",
    "    except:\n",
    "        return default\n",
    "    \n",
    "def fix_roi_name(roi):\n",
    "    roi = roi.lower()\n",
    "    if roi not in Const.organ_associations:\n",
    "        if 'gtv' in roi or 'rtv' in roi:\n",
    "            if 'gtvn' in roi or 'node' in roi or 'nodal' in roi:\n",
    "                return 'gtvn'\n",
    "            else:\n",
    "                return 'gtv'\n",
    "        if 'ptv' in roi:\n",
    "            return 'ptv'\n",
    "        if 'ctv' in roi:\n",
    "            return 'ctv'\n",
    "        return Const.organ_associations.get(roi.replace(' ','_').replace('cavity_oral','oral_cavity'),roi)\n",
    "    return Const.organ_associations.get(roi,roi)\n",
    "\n",
    "def read_rt_struct(rtstruct,contour_dict = None,associations=None):\n",
    "    #this should read an rtstruct file, clean the names\n",
    "    #returns a dict of {roi: [pointcloud,pointclouds...]}\n",
    "    #multiple pointclouds if there are different contours that are name varaints of a single organ (list gtv)\n",
    "    \n",
    "    #pass contour dict if there are mutliple rt struct files?\n",
    "    if contour_dict is None:\n",
    "        contour_dict = {}\n",
    "    if associations is None:\n",
    "        associations=Const.organ_associations\n",
    "        \n",
    "\n",
    "    rseq_list = get_element(rtstruct,'ROIContourSequence',[])\n",
    "    roi_list = get_element(rtstruct,'StructureSetROISequence',[])\n",
    "    if len(rseq_list) < 1 or len(roi_list) < 1:\n",
    "        return False\n",
    "    assert(len(rseq_list) == len(roi_list))\n",
    "    for rcseq,roi in zip(rseq_list,roi_list):\n",
    "        try:\n",
    "            \n",
    "            name = fix_roi_name(roi.ROIName)\n",
    "            number = roi.ROINumber\n",
    "            if 'ContourSequence' in rcseq:\n",
    "                cs = rcseq.ContourSequence\n",
    "                #each contourSequence is at a different z-height, so Imma just merge them\n",
    "                contours = [np.array(s.ContourData).reshape(-1,3) for s in rcseq.ContourSequence if len(s.ContourData) > 0]\n",
    "                contours = np.vstack(contours)\n",
    "                curr_entry = contour_dict.get(name,[])\n",
    "                curr_entry.append(contours)\n",
    "                contour_dict[name] = curr_entry\n",
    "        except Exception as e:\n",
    "            print('error in read_rt_struct',e)\n",
    "    return contour_dict\n",
    "\n",
    "# fix_roi_name('dsfsdgtv')\n",
    "# dicom_files[3194171650]['RT Dose Storage'][0]\n",
    "# read_rt_struct(rt_struct_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f345f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dose_pointcloud(dose,threshold=0):\n",
    "    data = dose['data']\n",
    "    if threshold is None:\n",
    "        threshold = data.min()\n",
    "    contour = np.argwhere(data.T > threshold)\n",
    "    (cx,cy,cz) = np.where(data.T > threshold)\n",
    "    point_values = data.T[cx,cy,cz].ravel()\n",
    "    return {'points': contour, 'values': point_values}\n",
    "\n",
    "def points_to_spatial(points, location, gridsize):\n",
    "    scale = np.array(gridsize)\n",
    "    corner = np.array(location)\n",
    "    newpoints = points*scale + corner\n",
    "    return  newpoints\n",
    "\n",
    "def dose_pcloud(dose,scale=None,**kwargs):\n",
    "    cloud = get_dose_pointcloud(dose,**kwargs)\n",
    "    spacing = dose['spacing']\n",
    "    location = dose['location']\n",
    "    thickness = dose['thickness']\n",
    "    if thickness is None or thickness <= 0: #missing, assume 3\n",
    "        thickness = 3\n",
    "    grid =np.array([spacing[0],spacing[1],thickness])\n",
    "    if scale is not None:\n",
    "        grid = grid*scale\n",
    "    coords = points_to_spatial(cloud['points'],location,grid)\n",
    "    return {'coordinates': coords, 'values': cloud['values']}\n",
    "\n",
    "def pointcloud_subset(pcloud, contour,values,slice_thickness=2):\n",
    "    #given a pointcloud pc and a pointlcoud countour(that is a contour) calculate points in pc that are inside the contour\n",
    "    zvals =  np.unique(contour[:,2])\n",
    "    zmax = zvals.max()\n",
    "    zmin = zvals.min()\n",
    "    below = pcloud[:,2] < zmax\n",
    "    above = pcloud[:,2] > zmin\n",
    "    within = below & above\n",
    "    pc = pcloud[within]\n",
    "    vals = values[within]\n",
    "    good_points = []\n",
    "    good_values = []\n",
    "    for z in zvals:\n",
    "        cslice = contour[contour[:,2] == z]\n",
    "        if cslice.shape[0] < 4:\n",
    "            continue\n",
    "        poly = Polygon(cslice)\n",
    "        in_subset = (np.absolute(pc[:,2] - z) <= slice_thickness/2)\n",
    "        point_subset = pc[in_subset]\n",
    "        val_subset = vals[in_subset]\n",
    "        is_good = [poly.contains(Point(p)) for p in point_subset]\n",
    "        good_points.extend(point_subset[is_good])\n",
    "        good_values.extend(val_subset[is_good])\n",
    "    if len(good_points) < 1:\n",
    "        return [[],[]]\n",
    "    return [np.stack(good_points),np.array(good_values)]\n",
    "\n",
    "def pointcloud_overlap(pcloud, contour,slice_thickness=0):\n",
    "    #given a pointcloud pc and a pointlcoud countour(that is a contour) calculate points in pc that are inside the contour\n",
    "    zvals =  np.unique(contour[:,2])\n",
    "    zmax = zvals.max()\n",
    "    zmin = zvals.min()\n",
    "    below = pcloud[:,2] < zmax\n",
    "    above = pcloud[:,2] > zmin\n",
    "    within = below & above\n",
    "    pc = pcloud[within]\n",
    "    max_overlap = 0\n",
    "    for z in zvals:\n",
    "        cslice = contour[contour[:,2] == z]\n",
    "        if cslice.shape[0] < 4:\n",
    "            continue\n",
    "        poly = Polygon(cslice)\n",
    "        in_subset = (np.absolute(pc[:,2] - z) <= slice_thickness/2)\n",
    "        point_subset = pc[in_subset]\n",
    "        for p in point_subset:\n",
    "            point = Point(p)\n",
    "            if poly.contains(point):\n",
    "                dist = poly.exterior.distance(point)\n",
    "                if dist > max_overlap:\n",
    "                    max_overlap = dist\n",
    "    return max_overlap\n",
    "\n",
    "def get_dose_roi_intersections(pdict,roilist=None):\n",
    "    contours = pdict['contours']\n",
    "    dosecloud = pdict['dose_pointcloud']['coordinates']\n",
    "    dosevals = pdict['dose_pointcloud']['values']\n",
    "    thickness = pdict['dose']['thickness']\n",
    "    if roilist is None:\n",
    "        roilist = list(contours.keys())\n",
    "    results = {}\n",
    "    for roi in roilist:\n",
    "        contourlist = contours.get(roi,[])\n",
    "        rlist = []\n",
    "        dlist = []\n",
    "        for contour in contourlist:\n",
    "            points,vals = pointcloud_subset(dosecloud,contour,dosevals,slice_thickness=thickness)\n",
    "            if len(points) > 0:\n",
    "                rlist.append(points)\n",
    "                dlist.extend(list(vals))\n",
    "        if len(rlist) > 0:\n",
    "            results[roi] = {'coordinates': np.vstack(rlist), 'dose_values': np.array(dlist)}\n",
    "    return results\n",
    "\n",
    "def pointcloud_distance_batched(pc1,pc2,batch_size=200,metric='euclidean',check_overlap=True):\n",
    "    #get two pointcloud arrays, checks distance between each pair of points\n",
    "    #returns the smallest distance (inter-organ distance)\n",
    "    if np.array(pc1).shape[0] < 2 or np.array(pc2).shape[0] < 2:\n",
    "        return False\n",
    "    \n",
    "    if check_overlap:\n",
    "        overlap = pointcloud_overlap(pc1,pc2)\n",
    "        if overlap > 0:\n",
    "            return -overlap\n",
    "        \n",
    "    pc1_batches = np.array_split(pc1,batch_size,axis=0)\n",
    "    min_dist = 10000000\n",
    "    for batch in pc1_batches:\n",
    "        if len(batch)  > 1:\n",
    "            batch_dists = cdist(batch,pc2,metric)\n",
    "            batch_min = batch_dists.min()\n",
    "            if batch_min < min_dist:\n",
    "                min_dist = batch_min\n",
    "    if min_dist == 10000000:\n",
    "        return 0\n",
    "    return min_dist\n",
    "\n",
    "def pcloud_dist_worker(args):\n",
    "    if len(args) != 2:\n",
    "        return 0\n",
    "    (pc1, pc2) = args\n",
    "    if pc1 is None or pc2 is None or len(pc1) < 1 or len(pc2) < 1:\n",
    "        return 0\n",
    "    return pointcloud_distance_batched(np.vstack(pc1),np.vstack(pc2))\n",
    "\n",
    "def interorgan_distances(pclouds,sources=None,targets=None,n_jobs=-2):\n",
    "    #assumes a dict of {roi: Nx3 array of poitns, roi2...}\n",
    "    keys = list(pclouds.keys())\n",
    "    if sources is None:\n",
    "        sources = keys\n",
    "    if targets is None:\n",
    "        targets = keys\n",
    "\n",
    "    distances = []\n",
    "    for source in sources:\n",
    "        scloud = pclouds.get(source)\n",
    "        if scloud is None:\n",
    "            dists = [0 for i in targets]\n",
    "        else:\n",
    "            dists = joblib.Parallel(n_jobs=n_jobs)( joblib.delayed(pcloud_dist_worker)((scloud,pclouds.get(target,[]))) for target in targets)\n",
    "        distances.append(dists)\n",
    "    return  distances\n",
    "\n",
    "\n",
    "# dose_pcloud(pdict_spatial[0]['dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DicomProcessor():\n",
    "\n",
    "    \n",
    "    def __init__(self,dicom_files = None, path = None, max_count = 40):\n",
    "        if dicom_files is None:\n",
    "            dicom_files = self.read_dicoms(path)\n",
    "        self.dicoms=dicom_files    \n",
    "        self.uids = list(dicom_files.keys())\n",
    "        self.active_uid =  self.uids[0]\n",
    "        \n",
    "    def read_dicoms(self,path,max_count=None):\n",
    "        files = glob.glob(path)\n",
    "        dicom_files = {}\n",
    "        for f in files:\n",
    "            p = pydicom.dcmread(f)\n",
    "            pid = str(p.PatientName)\n",
    "            entry = dicom_files.get(pid,{})\n",
    "            dtype = str(p.SOPClassUID.name)\n",
    "            if dtype not in ['RT Dose Storage','RT Structure Set Storage']:\n",
    "                continue\n",
    "            subentry = entry.get(dtype,[])\n",
    "            subentry.append(p)\n",
    "            entry[dtype] = subentry\n",
    "            dicom_files[pid] = entry\n",
    "            if max_count is not None and len(dicom_files) >= max_count:\n",
    "                break\n",
    "        return dicom_files\n",
    "    \n",
    "    def get_patient(self,uid=None):\n",
    "        if uid is None:\n",
    "            uid = self.active_uid\n",
    "        return self.dicoms.get(uid)\n",
    "    \n",
    "    def get_all_patients(self):\n",
    "        plist = [(uid,self.dicoms.get(uid)) for uid in self.uids]\n",
    "        return plist\n",
    "    \n",
    "def get_dicom_spatial(ds):\n",
    "    position = get_element(ds,'ImagePositionPatient')\n",
    "    orientation = get_element(ds,'ImageOrientationPatient')\n",
    "    slice_thickness = get_element(ds,'SliceThickness')\n",
    "    loc = get_element(ds,'SliceLocation')\n",
    "    spacing = get_element(ds,'PixelSpacing')\n",
    "    data = ds.pixel_array\n",
    "    entry = {\n",
    "        'data': data,\n",
    "        'position': position,\n",
    "        'orientation': orientation,\n",
    "        'location': loc,\n",
    "        'spacing': spacing,\n",
    "        'slice_thickness': float(slice_thickness) if slice_thickness else 3.0,\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "def get_dicom_identifiers(ds):\n",
    "    #these should alway be present\n",
    "    study_uid = ds.StudyInstanceUID\n",
    "    series_uid = ds.SeriesInstanceUID\n",
    "    class_uid = str(ds.SOPClassUID.name) #shouldn't be optional\n",
    "    pid = str(ds.PatientID)\n",
    "    entry = {\n",
    "        'patient_id': pid,\n",
    "        'study_uid': study_uid,\n",
    "        'series_uid': series_uid,\n",
    "        'type': class_uid,\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "def check_consistency(ct_images,identifiers):\n",
    "    identifiers = get_dicom_identifiers(ct_images[0]) if identifiers is None else identifiers\n",
    "    #just check for no\n",
    "    flag = True\n",
    "    for ct in ct_images:\n",
    "        temp_identifiers = get_dicom_identifiers(ct)\n",
    "        for k,v in temp_identifiers.items():\n",
    "            if 'series' not in k and 'type' not in k and identifiers[k] != v:\n",
    "                print('consistency error',k,v,identifiers[k])\n",
    "                flag = False\n",
    "    return flag\n",
    "\n",
    "def save_individual_patient(pdict,folder=None):\n",
    "    folder = Const.pointcloud_dir if folder is None else folder\n",
    "    fname = folder + 'pclouds_' + str(pdict['patient_id'])\n",
    "    contour_name = folder + 'contours_' + str(pdict['patient_id'])\n",
    "    to_keep = ['patient_id',\n",
    "               'study_uid',\n",
    "               'series_uid',\n",
    "               'spacing','contours',\n",
    "               'contour_pointclouds',\n",
    "               'missing_rois',\n",
    "               'extra_rois'\n",
    "              ]\n",
    "    entry = {k:pdict.get(k) for k in to_keep}\n",
    "    with open(fname+'.json','w') as f:\n",
    "        simplejson.dump(entry,f,default=np_converter)\n",
    "    with open(contour_name+'.json','w') as f2:\n",
    "        simplejson.dump(pdict['dose_pointcloud'],f2,default=np_converter)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def process_patient(pdict,save=True):\n",
    "    dose_data = pdict.get('RT Dose Storage')\n",
    "    rt_structs = pdict.get('RT Structure Set Storage')\n",
    "    entry = get_dicom_identifiers(dose_data[0])\n",
    "    is_good = check_consistency(dose_data,entry)\n",
    "    is_good = is_good and check_consistency(rt_structs,entry)\n",
    "    if not is_good:\n",
    "        return False\n",
    "    contours ={}\n",
    "    for rtstruct in rt_structs:\n",
    "        contours = read_rt_struct(rtstruct,contour_dict=contours)\n",
    "\n",
    "    entry['contours'] = contours\n",
    "    all_rois = set(contours.keys())\n",
    "    entry['missing_rois'] = [c for c in Const.organ_list + ['gtv','gtvn','ptv','ctv'] if c not in all_rois]\n",
    "    entry['extra_rois'] = [c for c in all_rois if c not in Const.organ_list + ['gtv','gtvn','ctv','ptv']]\n",
    "    print('missing rois',entry['missing_rois'])\n",
    "    print('extra rois:',entry['extra_rois'])\n",
    "    \n",
    "    dose_spatial = []\n",
    "    for dsi in dose_data:\n",
    "        spatial = get_dicom_spatial(dsi)\n",
    "        dose_spatial.append(spatial)\n",
    "            \n",
    "    topi = lambda array,i: np.min([d['position'][i] for d in array])\n",
    "    dose_corner = (topi(dose_spatial,0),topi(dose_spatial,1),topi(dose_spatial,2))\n",
    "    \n",
    "    dose_data = dose_spatial[0]['data']\n",
    "    #idk if this works yet, but they mentioned summing up voxels for muliple dose files\n",
    "    #i dont see that in the current data so idk\n",
    "    if len(dose_spatial) > 1:\n",
    "        for d in dose_spatial[1:]:\n",
    "            dose_data = dose_data + d['data']\n",
    "            \n",
    "    dose_entry = {\n",
    "        'location': dose_corner,\n",
    "        'spacing': dose_spatial[0]['spacing'],\n",
    "        'orientation': dose_spatial[0]['orientation'],\n",
    "        'thickness': dose_spatial[0]['slice_thickness'],\n",
    "        'data': dose_data,\n",
    "        'data_shape': dose_data.shape\n",
    "    }\n",
    "    \n",
    "    dose_cloud = dose_pcloud(dose_entry) #coordinates, values\n",
    "    entry['dose'] = dose_entry\n",
    "    entry['dose_pointcloud'] = dose_cloud\n",
    "\n",
    "    print('running getting contours',entry['patient_id'])\n",
    "    valid_rois = [c for c in all_rois if c in Const.organ_list[:] + ['gtv','gtvn','ptv','ctv']]\n",
    "    entry['contour_pointclouds'] = get_dose_roi_intersections(entry,roilist=valid_rois)\n",
    "    print('got contours, missing',[c for c in valid_rois if c not in entry['contour_pointclouds'].keys()])\n",
    "    print(dose_entry['thickness'],dose_entry['spacing'])\n",
    "    if save:\n",
    "        save_individual_patient(entry)\n",
    "    return entry \n",
    "\n",
    "\n",
    "def process_dicoms_spatial(dicom_files=None,path=None,skip_finished=True,calc_dists=True):\n",
    "    if path is None:\n",
    "        path = Const.unprocessed_dicoms + '**/**/**'\n",
    "    dp = DicomProcessor(dicom_files=dicom_files,path=path)\n",
    "    plist = []\n",
    "    dfilename = Const.small_dist_json\n",
    "    try:\n",
    "        with open(dfilename,'r') as f:\n",
    "            dfile = simplejson.load(f)\n",
    "            distances = dfile['distances']\n",
    "    except:\n",
    "        distances = {}\n",
    "        dfile = {'distances': distances} \n",
    "        \n",
    "    sources = ['gtv','gtvn']\n",
    "    targets = Const.organ_list[:]\n",
    "    dfile['rowOrder'] = sources\n",
    "    dfile['colOrder'] = targets\n",
    "    for (pid,pfiles) in dp.get_all_patients():\n",
    "        if int(pid) in [3192926363]:\n",
    "            continue\n",
    "        print('__________\\n')\n",
    "        print('new patient',pid)\n",
    "        p = process_patient(pfiles)\n",
    "        if p:\n",
    "            plist.append(p)\n",
    "            if calc_dists:\n",
    "                pdists = interorgan_distances(p['contours'],sources=sources, targets = targets)\n",
    "                distances[pid] = pdists.astype('float16')\n",
    "                print('distances',distances)\n",
    "                try:\n",
    "                    with open(dfilename,'w') as f:\n",
    "                        dfile['distances'] = distances\n",
    "                        simplejson.dump(dfile,f,default=np_converter)\n",
    "                except Exception as e:\n",
    "                    print('issue saving at pid',pid)\n",
    "                    print(e)\n",
    "        else:\n",
    "            print('issue getting ',pid)\n",
    "    return plist\n",
    "\n",
    "#this code runs the original processing\n",
    "\n",
    "test = ['placeholder','placehodler']\n",
    "while len(test) > 1:\n",
    "    test = process_dicoms_spatial(dicom_files=load_dicoms(sample_size=10))\n",
    "test\n",
    "# process_dicoms_spatial(dicom_files=load_dicoms_by_ids([4646292867, 9643148771]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce1baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyoid',\n",
       " 'mandible',\n",
       " 'brainstem',\n",
       " 'oral_cavity',\n",
       " 'glottis',\n",
       " 'thyroid',\n",
       " 'cricoid',\n",
       " 'cricopharyngeal_muscle',\n",
       " 'esophagus',\n",
       " 'glnd_submand_l',\n",
       " 'glnd_submand_r',\n",
       " 'genioglossus_m',\n",
       " 'glottis',\n",
       " 'hard_palate',\n",
       " 'soft_palate',\n",
       " 'ipc',\n",
       " 'spc',\n",
       " 'mpc',\n",
       " 'parotid_l',\n",
       " 'parotid_r',\n",
       " 'larynx',\n",
       " 'supraglottic_larynx',\n",
       " 'lips_lower',\n",
       " 'lips_upper',\n",
       " 'ant_digastric_l',\n",
       " 'ant_digastric_r',\n",
       " 'mastoid_l',\n",
       " 'mastoid_r',\n",
       " 'medial_pterygoid_l',\n",
       " 'medial_pterygoid_r',\n",
       " 'lateral_pterygoid_l',\n",
       " 'lateral_pterygoid_r',\n",
       " 'buccinator_l',\n",
       " 'buccinator_r',\n",
       " 'masseter_l',\n",
       " 'masseter_r',\n",
       " 'post_digastric_l',\n",
       " 'post_digastric_r',\n",
       " 'sternocleidomastoid_l',\n",
       " 'sternocleidomastoid_r',\n",
       " 'mylogeniohyoid',\n",
       " 'post_scalene_l',\n",
       " 'post_scalene_r',\n",
       " 'ant_scalene_l',\n",
       " 'ant_scalene_r',\n",
       " 'spinal_cord',\n",
       " 'tongue',\n",
       " 'pituitary']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Const.organ_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see that they are all encoded properly\n",
    "def load_pcloud(pid):\n",
    "    fname =Const.pointcloud_dir + 'pclouds_' + str(int(pid)) + '.json'\n",
    "    try:\n",
    "        with open(fname,'r') as f:\n",
    "            data = simplejson.load(f)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def validate_data(return_data=False,fix=True):\n",
    "    pids = get_finished_pids()\n",
    "    good = []\n",
    "    bad = []\n",
    "    for pid in pids:\n",
    "        pdata = load_pcloud(pid)\n",
    "        if pdata:\n",
    "            if return_data:\n",
    "                good.append(pdata)\n",
    "            else:\n",
    "                good.append(pid)\n",
    "        else:\n",
    "            bad.append(pid)\n",
    "    print('bad pids',bad)\n",
    "    if fix:\n",
    "        process_dicoms_spatial(dicom_files=load_dicoms_by_ids(bad))\n",
    "    return good, bad\n",
    "# validate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extra_rois(pids=None):\n",
    "    if pids is None:\n",
    "        pids = get_finished_pids()\n",
    "    def big_if_true(name,array):\n",
    "        array = list(set(array))\n",
    "        if len(array) > 1:\n",
    "            print(name,' | '.join(array))\n",
    "            print()\n",
    "    all_candidates = set([])\n",
    "    all_extra = set([])\n",
    "    for pid in pids:\n",
    "        pdata = load_pcloud(pid)\n",
    "        if pdata:\n",
    "            print('_____',pid,'________')\n",
    "            all_rois = pdata['contours'].keys()\n",
    "            needed_rois = pdata['contour_pointclouds'].keys()\n",
    "            missing = [c for c in Const.organ_list[:] + ['gtv','gtvn','ptv','ctv'] if c not in all_rois]\n",
    "            extra = [c for c in all_rois if c not in Const.organ_list[:] + ['gtv','gtvn','ptv','ctv'] ]\n",
    "            candidates = []\n",
    "            for r in extra:\n",
    "                for c in Const.organ_list + ['submand','smg','spinal','gland']:\n",
    "                    if c.replace('_l','').replace('_r','') in r:\n",
    "                        candidates.append(r)\n",
    "                        all_candidates.add(r)\n",
    "            for e in extra:\n",
    "                all_extra.add(e)\n",
    "            big_if_true('needed',needed_rois)\n",
    "            big_if_true('candidates',candidates)\n",
    "            big_if_true('extra',extra)\n",
    "            print('__________')\n",
    "    print('all candidates', ' | '.join(all_candidates))\n",
    "    print('____')\n",
    "    print('all extra', ' | '.join(all_extra))\n",
    "# show_extra_rois()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbefb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: ask about stuff like 'dose 62--[cgy] fs 66.8gy, etc and if that is likea ptv or something\n",
    "def get_extra_rois_candidates(pids=None):\n",
    "    if pids is None:\n",
    "        pids = get_finished_pids()\n",
    "  \n",
    "    candidates = {}\n",
    "    for pid in pids:\n",
    "        pdata = load_pcloud(pid)\n",
    "        if pdata:\n",
    "            print('_____',pid,'________')\n",
    "            all_rois = pdata['contours'].keys()\n",
    "            extra = [c for c in all_rois if c not in Const.organ_list[:] + ['gtv','gtvn','ptv','ctv'] ]\n",
    "            for r in extra:\n",
    "                for c in Const.organ_list + ['submand','smg','spinal','gland']:\n",
    "                    if c.replace('_l','').replace('_r','') in r:\n",
    "                        candidates[r] = c\n",
    "    for k,v in Const.organ_associations.items():\n",
    "        candidates[k] = v\n",
    "    return candidates\n",
    "# get_extra_rois_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78742e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_distances(dfilename=None,skip_finished=True,root=None):\n",
    "    if dfilename is None:\n",
    "        dfilename = Const.full_dist_json\n",
    "    if root is None:\n",
    "        root = Const.pointcloud_dir\n",
    "    try:\n",
    "        with open(dfilename,'r') as f:\n",
    "            dfile = simplejson.load(f)\n",
    "            distances = dfile['distances']\n",
    "    except:\n",
    "        distances = {}\n",
    "        dfile = {'distances': distances}\n",
    "    processed_patients = glob.glob(root+ 'pclouds_*.json')\n",
    "    sources = ['gtv','gtvn'] + Const.organ_list[:]\n",
    "    targets = Const.organ_list[:]\n",
    "    dfile['rowOrder'] = sources\n",
    "    dfile['targetOrder'] = targets\n",
    "    for file in processed_patients:\n",
    "        pid = int(file.replace( root+'pclouds_','').replace('.json',''))\n",
    "        if skip_finished and pid in distances:\n",
    "            continue\n",
    "        print('running',pid)\n",
    "        try:\n",
    "            with open(file,'r') as f:\n",
    "                pdict = simplejson.load(f)\n",
    "            contours = {k: [np.array(vv) for vv in v] for k,v in pdict['contours'].items()}\n",
    "            print('contours loaded')\n",
    "            pdists = interorgan_distances(contours,sources=sources,targets=targets)\n",
    "            distances[pid] = pdists \n",
    "            with open(dfilename,'w') as f:\n",
    "                dfile['distances'] = distances\n",
    "                simplejson.dump(dfile,f,default=np_converter)\n",
    "            print(pid,'done',len(distances))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('error reading distances',e)\n",
    "            print('______________')\n",
    "    return distances\n",
    "    \n",
    "#json with gtv/gtvn + organ -> organ distances\n",
    "#row order is gtv,gtvn,Const.organ_list, col: const.organ_list\n",
    "full_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_distances(dfilename=None,skip_finished=True,root=None):\n",
    "    if dfilename is None:\n",
    "        dfilename = Const.small_dist_json\n",
    "    if root is None:\n",
    "        root = Const.pointcloud_dir\n",
    "    try:\n",
    "        with open(dfilename,'r') as f:\n",
    "            dfile = simplejson.load(f)\n",
    "            distances = dfile['distances']\n",
    "    except:\n",
    "        distances = {}\n",
    "        dfile = {'distances': distances}\n",
    "    processed_patients = glob.glob(root+ 'pclouds_*.json')\n",
    "    sources = ['gtv','gtvn']\n",
    "    targets = Const.organ_list[:]\n",
    "    dfile['rowOrder'] = sources\n",
    "    dfile['targetOrder'] = targets\n",
    "    for file in processed_patients:\n",
    "        pid = int(file.replace( root+'pclouds_','').replace('.json',''))\n",
    "        if skip_finished and pid in distances:\n",
    "            continue\n",
    "        print('running',pid)\n",
    "        try:\n",
    "            with open(file,'r') as f:\n",
    "                pdict = simplejson.load(f)\n",
    "            contours = {k: [np.array(vv) for vv in v] for k,v in pdict['contours'].items()}\n",
    "            print('contours loaded')\n",
    "            pdists = interorgan_distances(contours,sources=sources,targets=targets)\n",
    "            distances[pid] = pdists \n",
    "            with open(dfilename,'w') as f:\n",
    "                dfile['distances'] = distances\n",
    "                simplejson.dump(dfile,f,default=np_converter)\n",
    "            print(pid,'done',len(distances))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('error reading distances',e)\n",
    "            print('______________')\n",
    "    return distances\n",
    "    \n",
    "#json with gtv/gtvn + organ -> organ distances\n",
    "#row order is gtv,gtvn,Const.organ_list, col: const.organ_list\n",
    "small_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_distances(dfilename=None,skip_finished=True,root=None):\n",
    "    if dfilename is None:\n",
    "        dfilename = Const.full_dist_json\n",
    "    if root is None:\n",
    "        root = Const.pointcloud_dir\n",
    "    try:\n",
    "        with open(dfilename,'r') as f:\n",
    "            dfile = simplejson.load(f)\n",
    "            distances = dfile['distances']\n",
    "    except:\n",
    "        distances = {}\n",
    "        dfile = {'distances': distances}\n",
    "    processed_patients = glob.glob(root+ 'pclouds_*.json')\n",
    "    sources = ['gtv','gtvn'] + Const.organ_list[:]\n",
    "    targets = Const.organ_list[:]\n",
    "    dfile['rowOrder'] = sources\n",
    "    dfile['targetOrder'] = targets\n",
    "    for file in processed_patients:\n",
    "        pid = int(file.replace( root+'pclouds_','').replace('.json',''))\n",
    "        if skip_finished and pid in distances:\n",
    "            continue\n",
    "        print('running',pid)\n",
    "        try:\n",
    "            with open(file,'r') as f:\n",
    "                pdict = simplejson.load(f)\n",
    "            contours = {k: [np.array(vv) for vv in v] for k,v in pdict['contours'].items()}\n",
    "            print('contours loaded')\n",
    "            pdists = interorgan_distances(contours,sources=sources,targets=targets)\n",
    "            distances[pid] = pdists \n",
    "            with open(dfilename,'w') as f:\n",
    "                dfile['distances'] = distances\n",
    "                simplejson.dump(dfile,f,default=np_converter)\n",
    "            print(pid,'done',len(distances))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('error reading distances',e)\n",
    "            print('______________')\n",
    "    return distances\n",
    "    \n",
    "\n",
    "def get_dose_roi_intersections(pdict,roilist=None):\n",
    "    contours = pdict['contours']\n",
    "    dosecloud = np.array(pdict['dose_pointcloud']['coordinates'])\n",
    "    dosevals = np.array(pdict['dose_pointcloud']['values'])\n",
    "    thickness = pdict['dose']['thickness']\n",
    "    if roilist is None:\n",
    "        roilist = list(contours.keys())\n",
    "    results = {}\n",
    "    for roi in roilist:\n",
    "        contourlist = contours.get(roi,[])\n",
    "        rlist = []\n",
    "        dlist = []\n",
    "        for contour in contourlist:\n",
    "            contour = np.array(contour)\n",
    "            points,vals = pointcloud_subset(dosecloud,contour,dosevals,slice_thickness=thickness)\n",
    "            if len(points) > 0:\n",
    "                rlist.append(points)\n",
    "                dlist.extend(list(vals))\n",
    "        if len(rlist) > 0:\n",
    "            results[roi] = {'coordinates': np.vstack(rlist), 'dose_values': np.array(dlist)}\n",
    "    return results\n",
    "\n",
    "def fix_patients(root=None):\n",
    "    if root is None:\n",
    "        root = Const.pointcloud_dir\n",
    "    processed_patients = glob.glob(root+ 'pclouds_*.json')\n",
    "    fixed = []\n",
    "    skipped=[]\n",
    "    for file in processed_patients:\n",
    "        pid = int(file.replace( root+'pclouds_','').replace('.json',''))\n",
    "        print('running',pid)\n",
    "        try:\n",
    "            with open(file,'r') as f:\n",
    "                entry = simplejson.load(f)\n",
    "            if 'contour_pointclouds' not in entry:\n",
    "                print('fixing...')\n",
    "                entry['contours'] = {k: [np.array(vv) for vv in v] for k,v in entry['contours'].items()}\n",
    "                all_rois = set(entry['contours'].keys())\n",
    "                valid_rois = [c for c in all_rois if c in Const.organ_list[:] + ['gtv','gtvn']]\n",
    "                entry['dose'] = {'thickness': 3}\n",
    "                print('starting contouring')\n",
    "                entry['contour_pointclouds'] = get_dose_roi_intersections(entry,roilist=valid_rois)\n",
    "                print('finished contouring')\n",
    "                save_individual_patient(entry)\n",
    "                print('saved successful')\n",
    "                print('__________')\n",
    "                fixed.append(pid)\n",
    "            else:\n",
    "                skipped.append(pid)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('_________________')\n",
    "            skipped.append(pid)\n",
    "    return fixed,skipped\n",
    "\n",
    "fix_patients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c16837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../data/DICOMS/ProcessedPatients/pclouds_1334966362.json','r') as f:\n",
    "#     test = json.load(f)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daef166",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c497d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Qubbed]",
   "language": "python",
   "name": "conda-env-Qubbed-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
