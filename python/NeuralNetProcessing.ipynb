{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71916a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from Constants import Const\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92430a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 08:36:26.310429: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-12 08:36:26.362721: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import sparseconvnet as scn\n",
    "import open3d as o3d\n",
    "import open3d.ml.torch as ml3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49348742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pointclouds(pc_dir='../data/',max_num = 10000,bad_ids=Const.bad_ids):\n",
    "    files = glob.glob(pc_dir+'pclouds_*.json')\n",
    "    all_files = []\n",
    "    for file in files:\n",
    "        with open(file,'r') as f:\n",
    "            test = json.load(f)\n",
    "        if int(test['patient_id']) not in bad_ids:\n",
    "            all_files.append(test)\n",
    "        if len(all_files) > max_num:\n",
    "            break\n",
    "    return all_files\n",
    "# pointclouds = load_pointclouds()\n",
    "# len(pointclouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98638f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdasi_vector(pid,mdasi,symptoms  = None,threshold=5,confounders = None):\n",
    "    if symptoms is None:\n",
    "        symptoms = ['drymouth','pain','swallow','choke','voice','mucus','mucositis']\n",
    "    if confounders is None:\n",
    "        confounders = ['hpv']\n",
    "    entry = mdasi['data'].get(str(pid))\n",
    "    results = [entry[s+'_6M'] for s in symptoms]\n",
    "    if threshold is not None:\n",
    "        results = [int(r >= threshold) for r in results]\n",
    "    else:\n",
    "        results = [r/10 for r in results]\n",
    "    for confounder in confounders:\n",
    "        results.append(entry[confounder])\n",
    "    return np.array(results).astype(bool)\n",
    "\n",
    "def extract_dist(patient_id,dists,organs=None,gtvs=['gtv','gtvn']):\n",
    "    if organs is None:\n",
    "        organs = dists['colOrder']\n",
    "    colOrder = dists['colOrder']\n",
    "    oindexes = [colOrder.index(o) for o in organs]\n",
    "    patient = dists['distances'][str(patient_id)]\n",
    "    d = [[p[i] for i in oindexes]for ii,p in enumerate(patient) if dists['rowOrder'][ii] in gtvs]\n",
    "    d = np.array(d).min(axis=0)\n",
    "    return d\n",
    "\n",
    "def downsample_pointcloud(pcloud,k=1,max_points = 5000,pad=True):\n",
    "    pc = o3d.geometry.PointCloud()\n",
    "    pc.points = o3d.utility.Vector3dVector(pcloud['coordinates'])\n",
    "    #save dose as rgb color for when they're discretized\n",
    "    pc.colors = o3d.utility.Vector3dVector(np.stack([pcloud['dose_values'] for c in range(3)],axis=-1))\n",
    "    pc = pc.voxel_down_sample(k)#to make it uniform for the convolution\n",
    "    if len(pc.points) > max_points:\n",
    "        pc = pc.farthest_point_down_sample(max_points)\n",
    "    points = np.asarray(pc.points)\n",
    "    colors = np.asarray(pc.colors)[:,0]\n",
    "    if points.shape[0] < max_points and pad:\n",
    "        diff = max_points -points.shape[0] \n",
    "        padd = np.zeros((diff,3))\n",
    "        points = np.concatenate([points,padd],axis=0)\n",
    "        colors = np.concatenate([colors,padd[:,0]],axis=0)\n",
    "    return {'coordinates': points,'dose_values': colors}\n",
    "\n",
    "def get_patient_stuff(pentry,\n",
    "                dists_data,\n",
    "                mdasi_data,\n",
    "                organs = Const.organ_list,\n",
    "                gtvs=['gtv','gtvn'],\n",
    "                downsample_k=None,\n",
    "                max_points=2000,\n",
    "                pad=True,\n",
    "                symptoms=None,\n",
    "                torchify=True,\n",
    "                requires_grad=True,\n",
    "               ):\n",
    "    #processes patient, returns a list of [pointcloud coordinates,pointcloud dose values, distances, mdasi_vector]\n",
    "    #pointclouds and distacnes are in the predefined order, distacnes is min gtv-organ distances currently\n",
    "    #pointcloud stuff is a list of tensors (one for each organ)\n",
    "    cpc = pentry['contour_pointclouds']\n",
    "    pid = pentry['patient_id']\n",
    "    distances = extract_dist(pid,dists_data,organs=organs)\n",
    "    mdasi_stuff = get_mdasi_vector(pid,mdasi_data,symptoms=symptoms)\n",
    "    padsize = 10 if not pad else max_points\n",
    "    placeholder = {'coordinates': np.zeros((padsize,3)),'dose_values': np.zeros((padsize,1))}\n",
    "    coords = []\n",
    "    values = []\n",
    "    max_val = 0\n",
    "    for o in gtvs + organs:\n",
    "        vals = cpc.get(o)\n",
    "        if vals is not None and (downsample_k is not None or vals['coordinates'].shape[0] > max_points or pad):\n",
    "            mpoints = max_points if vals in organs else 10000000 #don't downsample tumors\n",
    "            vals = downsample_pointcloud(vals,downsample_k,mpoints,pad)\n",
    "        else:\n",
    "            vals = placeholder\n",
    "        coords.append(vals['coordinates'])\n",
    "        values.append(vals['dose_values'].reshape(-1,1))\n",
    "        if o in gtvs:\n",
    "            max_val = max(max_val,np.max(vals['dose_values']))\n",
    "    dose_scale = 100\n",
    "    if max_val > 13000:\n",
    "        dose_scale = 1000\n",
    "    if max_val > 130000:\n",
    "        dose_scale = 10000\n",
    "    values = [v/dose_scale for v in values]\n",
    "    if torchify:\n",
    "        coords = [torch.FloatTensor(c) for c in coords]\n",
    "        values = [torch.FloatTensor(v) for v in values]\n",
    "        if pad:\n",
    "            coords = torch.stack(coords)\n",
    "            values = torch.stack(values)\n",
    "#             coords.requires_grad_(requires_grad)\n",
    "#             values.requires_grad_(requires_grad)\n",
    "        distances = torch.FloatTensor(distances)\n",
    "#         distances.requires_grad_(requires_grad)\n",
    "        mdasi_stuff = torch.LongTensor(mdasi_stuff) #change if I ever do continuous mdasi features\n",
    "    output = [coords,values,distances,mdasi_stuff]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class DicomDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pc_files=None,#list of precompute patient dose pointclouds\n",
    "                 dist_json=None, #file with tumor-organ distances for each patient\n",
    "                 mdasi_json=None, #symptoms\n",
    "                 bad_ids = Const.bad_ids,#skip these\n",
    "                 dist_file = None,#if dist json is NOne, where to load from\n",
    "                 mdasi_file = None,#if mdasi_json is none, where to load\n",
    "                 symptoms =  ['drymouth','pain','choke','mucus'],\n",
    "                 confounders=[],\n",
    "                 organs = None,\n",
    "                 gtvs=None,\n",
    "                 max_pc_points=1000,\n",
    "                 voxel_size=1,\n",
    "                 pad = False,\n",
    "                 shuffle_on_init=True,\n",
    "                 outcome_weight_scale=.5,\n",
    "                 requires_grad=True,\n",
    "                ):\n",
    "        self.symptoms = symptoms\n",
    "        self.n_symptoms = len(symptoms)\n",
    "        self.max_pc_points = max_pc_points\n",
    "        self.voxel_size = voxel_size\n",
    "        \n",
    "        if organs is None:\n",
    "            organs = Const.organ_list[:]\n",
    "        if gtvs is None:\n",
    "            gtvs = ['gtv','gtvn']\n",
    "        self.organs = organs\n",
    "        self.gtvs = gtvs\n",
    "        self.confounders = confounders\n",
    "        self.pad = pad\n",
    "        \n",
    "        if pc_files is None:\n",
    "            pc_files = load_pointclouds()\n",
    "    \n",
    "        if dist_json is None:\n",
    "            if dist_file is None:\n",
    "                dist_file = Const.small_dist_json\n",
    "            with open(dist_file,'r') as f:\n",
    "                dist_json = json.load(f)\n",
    "        \n",
    "        if mdasi_json is None:\n",
    "            if mdasi_file is None:\n",
    "                mdasi_file = '../data/dicom_mdasi.json'\n",
    "            with open(mdasi_file,'r') as f:\n",
    "                mdasi_json = json.load(f)\n",
    "        \n",
    "        self.coords = []\n",
    "        self.values = []\n",
    "        self.distances = []\n",
    "        self.mdasi = []\n",
    "        for file in pc_files:\n",
    "            [c,v,d,m] = get_patient_stuff(file,\n",
    "                                                               dist_json,\n",
    "                                                               mdasi_json,\n",
    "                                                               pad=self.pad,\n",
    "                                                               organs=self.organs,\n",
    "                                                               gtvs=self.gtvs,\n",
    "                                                               downsample_k = voxel_size,\n",
    "                                                               max_points = self.max_pc_points,\n",
    "                                                               symptoms=self.symptoms,\n",
    "                                                              requires_grad=requires_grad,\n",
    "                                                              )\n",
    "            self.coords.append(c)\n",
    "            self.values.append(v)\n",
    "            self.distances.append(d)\n",
    "            self.mdasi.append(m)\n",
    "        self.normalizer = self.get_normalizer(self.values,self.gtvs+self.organs) \n",
    "        if shuffle_on_init:\n",
    "            self.shuffle()\n",
    "        else:\n",
    "            self.distances = torch.stack(self.distances)\n",
    "            self.mdasi = torch.stack(self.mdasi)\n",
    "\n",
    "        frequencies = self.mdasi.sum(axis=0)/self.mdasi.shape[0]\n",
    "        outcome_weights = 1/frequencies\n",
    "        outcome_weights = outcome_weights/outcome_weights.max()\n",
    "        self.outcome_weights = outcome_weights**outcome_weight_scale\n",
    "        self.require_grad = requires_grad\n",
    "            \n",
    "    def shuffle(self):\n",
    "        temp = list(zip(self.coords,self.values,self.distances,self.mdasi))\n",
    "        np.random.shuffle(temp)\n",
    "        c,v,d,m = zip(*temp)\n",
    "        self.coords = list(c)\n",
    "        self.values = list(v)\n",
    "        self.distances = list(d)\n",
    "        self.mdasi = list(m)\n",
    "        self.distances = torch.stack(self.distances)\n",
    "        self.mdasi = torch.stack(self.mdasi)\n",
    "        \n",
    "    def get_normalizer(self,val_lists,organs):\n",
    "        allvals = []\n",
    "        for patient in val_lists:\n",
    "            for l in patient:\n",
    "                if len(l) > 2:\n",
    "                    allvals.append(l)\n",
    "        allvals = torch.concat(allvals)\n",
    "        normalize = lambda x: (x - allvals.mean())/allvals.std()\n",
    "        return normalize\n",
    "    \n",
    "    def __len__(self):\n",
    "            return self.mdasi.shape[0]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        c = self.coords[idx]\n",
    "        v = [self.normalizer(vv) for vv in self.values[idx]]\n",
    "        d = self.distances[idx]\n",
    "        m = self.mdasi[idx]\n",
    "        return [c,v,d], m\n",
    "    \n",
    "def dicom_tt_split(all_files=None,test_ratio=.3,shuffle_split=False,shuffle_on_epoch = True,batch_size=10,**kwargs):\n",
    "    if all_files is None:\n",
    "        all_files = load_pointclouds()\n",
    "    if shuffle_split:\n",
    "        np.random.shuffle(all_files)\n",
    "    test_index = int(len(all_files)*test_ratio)\n",
    "    test_pcs = all_files[0:test_index]\n",
    "    train_pcs = all_files[test_index:]\n",
    "    train_dl = DicomDataset(pc_files=train_pcs,**kwargs)\n",
    "    test_dl = DicomDataset(pc_files=test_pcs,**kwargs)\n",
    "    device = get_device()\n",
    "    def collate(batch):\n",
    "        coords = []\n",
    "        vals = []\n",
    "        dists = []\n",
    "        mdasi = []\n",
    "        for [[c,v,d],m] in batch:\n",
    "            coords.append([cc.to(device) for cc in c])\n",
    "            vals.append([vv.to(device) for vv in v])\n",
    "            dists.append(d) #first value is # of channels, currentl assume only dose\n",
    "            mdasi.append(m)\n",
    "        ybatch = torch.stack(mdasi).to(device)\n",
    "        dists = torch.stack(dists).to(device)\n",
    "        xbatch = [coords,vals,dists]\n",
    "        return xbatch,ybatch\n",
    "    train_dl = torch.utils.data.DataLoader(train_dl,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=shuffle_on_epoch,\n",
    "                                           drop_last=False,\n",
    "                                           num_workers=3,\n",
    "                                           pin_memory=True,\n",
    "                                           collate_fn=collate)\n",
    "    test_dl = torch.utils.data.DataLoader(test_dl,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=False,\n",
    "                                          num_workers=3,\n",
    "                                           pin_memory=True,\n",
    "                                          collate_fn=collate)\n",
    "    return train_dl, test_dl\n",
    "\n",
    "[train_data,test_data] = dicom_tt_split()\n",
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b518b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SparseConvBlock(nn.Module):\n",
    "    #runs a batch of convolutions on a single pointcloud\n",
    "    def __init__(self,\n",
    "                 input_features,\n",
    "                 dims=3,\n",
    "                 filter_sizes=[32,32],\n",
    "                 kernel_sizes=[20,10],\n",
    "                 voxel_size=2,\n",
    "                 continuous=True,\n",
    "                ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.dims = dims\n",
    "        self.features=input_features\n",
    "        self.blockBatchNorm = nn.BatchNorm1d(filter_sizes[-1])\n",
    "        inputs = [input_features] + filter_sizes\n",
    "        makeConv = ml3d.layers.ContinuousConv\n",
    "        if not continuous:\n",
    "            makeConv = ml3d.layers.SparseConv\n",
    "        self.convolutions = nn.ModuleList([makeConv(inputs[i],filter_sizes[i],[kernel_sizes[i] for k in range(dims)]) for i in range(len(filter_sizes))])\n",
    "        self.voxel_pool = ml3d.layers.VoxelPooling(position_fn='center',feature_fn='max')\n",
    "        #for tracking organ positions\n",
    "        self.voxel_pool_nn = ml3d.layers.VoxelPooling(position_fn='center',feature_fn='nearest_neighbor')\n",
    "        self.voxel_size=voxel_size\n",
    "        \n",
    "    def forward(self,positions,features):\n",
    "        x = self.convolutions[0](features,positions,positions,1)\n",
    "        for conv in self.convolutions[1:]:\n",
    "            x = conv(x,positions,positions,1)\n",
    "#         x = self.blockBatchNorm(x.transpose(1,2)).transpose(1,2)\n",
    "#         positions, x = self.voxel_pool(positions,x,self.voxel_size)\n",
    "        return positions,x\n",
    "\n",
    "class SparseCNN(nn.Module):\n",
    "    #full cnn for a single pointcloud\n",
    "    def __init__(self,\n",
    "                 input_features,\n",
    "                 dims=3,\n",
    "                 filter_sizes=[[32,32],[32,32]],\n",
    "                 kernel_sizes=[[20,10],[20,10]],\n",
    "                 continuous=True,\n",
    "                 pool_size = 2,\n",
    "                ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.dims = dims\n",
    "        self.features=input_features\n",
    "        curr_size = input_features\n",
    "        self.blocks = []\n",
    "        self.inputNorm = nn.BatchNorm1d(input_features)\n",
    "        curr_pool_size = pool_size\n",
    "        for [filterblock, kernelblock] in zip(filter_sizes,kernel_sizes):\n",
    "            block = SparseConvBlock(curr_size,dims,filter_sizes=filterblock,kernel_sizes=kernelblock,continuous=continuous,voxel_size=curr_pool_size)\n",
    "            self.blocks.append( block)\n",
    "            curr_size = filterblock[-1]\n",
    "            curr_pool_size += 1\n",
    "        self.blocks = nn.ModuleList(self.blocks)\n",
    "        \n",
    "    def voxel_pool_nn(self,positions,features):\n",
    "        #for when I do a convolution and need to keep track of organ positions\n",
    "#         for block in self.blocks:\n",
    "#             positions,features = block.voxel_pool_nn(positions,features,block.voxel_size)\n",
    "        return positions, features\n",
    "        \n",
    "    def forward(self,positions,features):\n",
    "        x = features#self.inputNorm(features)\n",
    "        for block in self.blocks:\n",
    "            positions,x = block(positions,x)\n",
    "        return positions,x\n",
    "    \n",
    "class OrganNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_classes=8,\n",
    "                 n_organs=50,\n",
    "                 dist_dims=[1000],\n",
    "                 fc_dims=[500,500],\n",
    "                 fc_dropout = .5,\n",
    "                 sparse_cnn=None,\n",
    "                 organ_dropout=.5,\n",
    "                 **cnn_args\n",
    "                ):\n",
    "        super(OrganNet, self).__init__()\n",
    "        if sparse_cnn is None:\n",
    "            sparse_cnn = SparseCNN(1,*cnn_args)\n",
    "        self.cnn = sparse_cnn\n",
    "        self.dist_layers = nn.ModuleList([nn.LazyLinear(dd) for dd in dist_dims])\n",
    "        self.fc_layers = nn.ModuleList([nn.LazyLinear(dd) for dd in fc_dims])\n",
    "        self.fc_dropout = nn.Dropout(p=fc_dropout)\n",
    "#         self.full_dropout = torch.nn.Dropout(1)\n",
    "        self.organ_dropout = organ_dropout\n",
    "        self.activation = nn.ReLU()\n",
    "        self.final_linear = nn.Linear(fc_dims[-1],n_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.n_organs= 50\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "        \n",
    "    def forward(self,x,train=False):\n",
    "        [positions,features,distances] = x\n",
    "#         values = torch.zeros((distances.shape[0],self.n_organs),requires_grad=True)\n",
    "        values = []\n",
    "        for row,(plist, flist) in enumerate(zip(positions,features)): \n",
    "            vrow = []\n",
    "            prow = []\n",
    "            organ_indices=[]\n",
    "            #basically for each patient there is a list of pointclouds and a list of pointcloud features\n",
    "            #one for each organ. assumes in correct order with missing organs as an empty item\n",
    "            #does a convolution block on all points, then max-pools points for each individual organ, and concatenates the results\n",
    "            #final vector is (n_organs*features in last cnn block)\n",
    "            for col,(p,f) in enumerate(zip(plist,flist)):\n",
    "                if f.shape[0] < 2:\n",
    "                    f = torch.zeros((3,1)).to(self.dummy_param.device)\n",
    "                    p = torch.zeros((3,3)).to(self.dummy_param.device)\n",
    "                #stacks feature s and checks what position they're in (corresponds to organ)\n",
    "                #randomly set organs to zero during training for dropout\n",
    "                if self.train and self.organ_dropout > 0 and torch.rand(1).item() < self.organ_dropout:\n",
    "                    f = torch.zeros(f.shape).to(self.dummy_param.device)\n",
    "                vrow.append(f)\n",
    "                prow.append(p)\n",
    "                col_idx = torch.zeros(f.shape).to(self.dummy_param.device)\n",
    "                col_idx[:] = col\n",
    "                organ_indices.append(col_idx)\n",
    "            prow = torch.concatenate(prow)\n",
    "            vrow = torch.concatenate(vrow)\n",
    "            organ_indices = torch.concatenate(organ_indices)\n",
    "            new_positions,new_features = self.cnn(prow,vrow)\n",
    "            #cnn should have a helper function to do pooling using a nearest neighbors approach to track organ membership\n",
    "            _, organ_indices = self.cnn.voxel_pool_nn(prow,organ_indices)\n",
    "            organ_indices = organ_indices.view(-1)\n",
    "            pooled_values = []\n",
    "            #max pool organs seperately\n",
    "            for oi in range(self.n_organs):\n",
    "                idx = torch.argwhere(organ_indices == oi)\n",
    "                #we lose some organs in the voxel pooling stage\n",
    "                if idx.shape[0] > 0:\n",
    "                    ovals = torch.max(new_features[idx],axis=0)[0]\n",
    "                    pooled_values.append(ovals.view(-1))\n",
    "                else:\n",
    "                    pooled_values.append(torch.zeros(new_features.shape[-1]).to(self.dummy_param.device))\n",
    "            pooled_values = torch.stack(pooled_values)\n",
    "            values.append(pooled_values.view(-1))\n",
    "        #batch size x (n_organs*n_featuers in last cnn block)\n",
    "        values = torch.stack(values)\n",
    "        #fully connected layers of just intra-organ distances\n",
    "        dx = self.dist_layers[0](distances)\n",
    "        for layer in self.dist_layers[1:]:\n",
    "            dx = layer(dx)\n",
    "            dx = self.activation(dx)\n",
    "        #combined convolution and distances, then fully connected layers\n",
    "        x = torch.cat((dx,values),axis=1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        if train:\n",
    "            x = self.fc_dropout(x)\n",
    "        x = self.final_linear(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "test_data.dataset.mdasi.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8003166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drymouth', 'pain', 'choke', 'mucus']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.dataset.symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379f76e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': [0.5, 0.25, 0.0], 'f1': [0.0, 0.0, 0.5]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score , f1_score\n",
    "\n",
    "def multi_bce_loss(ypred,target,weights=[1,2,.4]):\n",
    "    nclasses = ypred.shape[1]\n",
    "    bce = nn.BCELoss()\n",
    "    total_loss = 0\n",
    "    for i in range(nclasses):\n",
    "        closs = bce(ypred[:,i],target[:,i].type(torch.FloatTensor))\n",
    "        total_loss += weights[i]*closs.item()\n",
    "        print(closs.item())\n",
    "    return total_loss\n",
    "\n",
    "def multiclass_metrics(ypred,target):\n",
    "    nclasses = ypred.shape[1]\n",
    "    ypred = ypred.detach().numpy().astype(float)\n",
    "    target = target.detach().numpy().astype(float)\n",
    "    aucs = []\n",
    "    f1s = []\n",
    "    for i in range(nclasses):\n",
    "        if target[:,i].std() < .0001:\n",
    "            auc_score = -1\n",
    "            f1_scores = -1\n",
    "        else:\n",
    "            auc_score = roc_auc_score(target[:,i],ypred[:,i])\n",
    "            f1_scores = f1_score(target[:,i],ypred[:].argmax(axis=1) == i)\n",
    "        aucs.append(auc_score)\n",
    "        f1s.append(f1_scores)\n",
    "    return {'auc': aucs, 'f1': f1s}\n",
    "multiclass_metrics(torch.rand(4,3),torch.LongTensor([[0,1,1],[1,0,0],[0,0,0],[1,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfae15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concatenate([torch.rand(4,3),torch.rand(5,3)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e39a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/tmp/ipykernel_17446/4186382088.py:156: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss tensor(1.2813, device='cuda:0', grad_fn=<AddBackward0>)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal losses\u001b[39m\u001b[38;5;124m'\u001b[39m,curr_loss_train,curr_loss_val,best_val_loss)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 79\u001b[0m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 62\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model, train_data, test_data, pc_files, batch_size, epochs, lr, patience)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target, pred, running_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_data\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 62\u001b[0m     curr_loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m,curr_loss_train)\n\u001b[1;32m     64\u001b[0m     ytrue, ypred, val_loss \u001b[38;5;241m=\u001b[39m val_loop()\n",
      "Cell \u001b[0;32mIn[12], line 36\u001b[0m, in \u001b[0;36mrun_model.<locals>.train_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xbatch, ybatch \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[0;32m---> 36\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(ypred,ybatch)\n\u001b[1;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 124\u001b[0m, in \u001b[0;36mOrganNet.forward\u001b[0;34m(self, x, train)\u001b[0m\n\u001b[1;32m    122\u001b[0m vrow \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(vrow)\n\u001b[1;32m    123\u001b[0m organ_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(organ_indices)\n\u001b[0;32m--> 124\u001b[0m new_positions,new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#cnn should have a helper function to do pooling using a nearest neighbors approach to track organ membership\u001b[39;00m\n\u001b[1;32m    126\u001b[0m _, organ_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn\u001b[38;5;241m.\u001b[39mvoxel_pool_nn(prow,organ_indices)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m, in \u001b[0;36mSparseCNN.forward\u001b[0;34m(self, positions, features)\u001b[0m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m features\u001b[38;5;66;03m#self.inputNorm(features)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 66\u001b[0m     positions,x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m positions,x\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mSparseConvBlock.forward\u001b[0;34m(self, positions, features)\u001b[0m\n\u001b[1;32m     26\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutions[\u001b[38;5;241m0\u001b[39m](features,positions,positions,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutions[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 28\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#         x = self.blockBatchNorm(x.transpose(1,2)).transpose(1,2)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#         positions, x = self.voxel_pool(positions,x,self.voxel_size)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m positions,x\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/open3d/ml/torch/python/layers/convolutions.py:270\u001b[0m, in \u001b[0;36mContinuousConv.forward\u001b[0;34m(self, inp_features, inp_positions, out_positions, extents, inp_importance, fixed_radius_search_hash_table, user_neighbors_index, user_neighbors_row_splits, user_neighbors_importance)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(extents\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    269\u001b[0m     radius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m extents\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_radius_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43minp_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhash_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_radius_search_hash_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_distances:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius_search_metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/open3d/ml/torch/python/layers/neighbor_search.py:135\u001b[0m, in \u001b[0;36mFixedRadiusSearch.forward\u001b[0;34m(self, points, queries, radius, points_row_splits, queries_row_splits, hash_table_size_factor, hash_table)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     table \u001b[38;5;241m=\u001b[39m hash_table\n\u001b[0;32m--> 135\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_radius_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_query_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_query_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_distances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_distances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints_row_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints_row_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries_row_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries_row_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_table_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_table_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_table_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_table_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_table_cell_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_table_cell_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/open3d/ml/torch/python/ops.py:877\u001b[0m, in \u001b[0;36mfixed_radius_search\u001b[0;34m(points, queries, radius, points_row_splits, queries_row_splits, hash_table_splits, hash_table_index, hash_table_cell_splits, index_dtype, metric, ignore_query_point, return_distances)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfixed_radius_search\u001b[39m(points,\n\u001b[1;32m    728\u001b[0m                         queries,\n\u001b[1;32m    729\u001b[0m                         radius,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    737\u001b[0m                         ignore_query_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    738\u001b[0m                         return_distances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    739\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the indices of all neighbors within a radius.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m    This op computes the neighborhood for each query point and returns the indices\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m      This is a zero length Tensor if 'return_distances' is False.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_types\u001b[38;5;241m.\u001b[39mfixed_radius_search(\n\u001b[0;32m--> 877\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[43m_torch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_radius_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoints_row_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints_row_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mqueries_row_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries_row_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhash_table_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_table_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhash_table_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_table_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhash_table_cell_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_table_cell_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_query_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_query_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_distances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distances\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_model(model=None,train_data=None,test_data=None,pc_files=None,batch_size=20,epochs = 100,lr=.000001,patience=5):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if train_data is None or test_data is None:\n",
    "        train_data, test_data = dicom_tt_split(all_files=pc_files,batch_size=batch_size)\n",
    "    n_classes = train_data.dataset.mdasi.shape[1]\n",
    "    loss_weights = train_data.dataset.outcome_weights\n",
    "    \n",
    "    if model is None:\n",
    "        model = OrganNet(n_classes= n_classes)\n",
    "    model = model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "    bce = nn.BCELoss()\n",
    "\n",
    "    def loss_fn(ypred,target):\n",
    "        total_loss = 0\n",
    "#         ypred = ypred.to(model.dummy_param.device)\n",
    "#         target = target.to(model.dummy_param.device)\n",
    "        target=target.type(torch.FloatTensor).to(device)\n",
    "        for i in range(n_classes):\n",
    "            temp = bce(ypred[:,i],target[:,i])\n",
    "            total_loss += loss_weights[i]*temp\n",
    "        return total_loss\n",
    "        \n",
    "    curr_loss_train = 0\n",
    "    curr_loss_val = 0\n",
    "    best_val_loss = 0\n",
    "    steps_since_improvement  = 0\n",
    "    steps_since_improvement\n",
    "    \n",
    "    def train_loop():\n",
    "        running_loss = 0\n",
    "        model.train(True)\n",
    "        steps = 0\n",
    "        for xbatch, ybatch in train_data:\n",
    "            ypred = model(xbatch)\n",
    "            loss = loss_fn(ypred,ybatch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            print('train loss',loss,end='\\r')\n",
    "        return running_loss/len(train_data.dataset)\n",
    "    \n",
    "    def val_loop():\n",
    "        running_loss = 0\n",
    "        model.train(False)\n",
    "        steps = 0\n",
    "        pred = []\n",
    "        target = []\n",
    "        for xbatch, ybatch in test_data:\n",
    "            ypred = model(xbatch)\n",
    "            pred.append(ypred)\n",
    "            target.append(ybatch)\n",
    "            loss = loss_fn(ypred,ybatch)\n",
    "            running_loss += loss.item()\n",
    "            print('val loss',loss,end='\\r')\n",
    "        target = torch.concatenate(target)\n",
    "        pred = torch.concatenate(pred)\n",
    "        return target, pred, running_loss/len(test_data.dataset)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        curr_loss_train = train_loop()\n",
    "        print('train loss',curr_loss_train)\n",
    "        ytrue, ypred, val_loss = val_loop()\n",
    "        print('val_loss',val_loss)\n",
    "        metrics = multiclass_metrics(ypred.detach().cpu(),ytrue.detach().cpu())\n",
    "        for k, v in metrics.items():\n",
    "            print('val '+k, [i + str(np.round(ii,2)) for i,ii in zip(train_data.dataset.symptoms,v)])\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            steps_since_improvement =0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('final losses',curr_loss_train,curr_loss_val,best_val_loss)\n",
    "    return model\n",
    "\n",
    "run_model(train_data=train_data,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet = _ml3d.utils.get_module('model','Pointnet2MSG','torch')\n",
    "pnet([test_l,test_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3122cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    print(len(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f77ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsample_pointcloud(pcloud,k=1,max_points = 5000):\n",
    "#     pc = o3d.geometry.PointCloud()\n",
    "#     pc.points = o3d.utility.Vector3dVector(pcloud['coordinates'])\n",
    "#     #save dose as rgb color for when they're discretized\n",
    "#     pc.colors = o3d.utility.Vector3dVector(np.stack([pcloud['dose_values'] for c in range(3)],axis=-1))\n",
    "#     pc = pc.voxel_down_sample(k)#to make it uniform for the convolution\n",
    "#     if len(pc.points) > max_points:\n",
    "#         pc = pc.farthest_point_down_sample(max_points)\n",
    "#     points = np.asarray(pc.points)\n",
    "#     colors = np.asarray(pc.colors)[:,0]\n",
    "#     if points.shape[0] < max_points:\n",
    "#         diff = max_points -points.shape[0] \n",
    "#         padd = np.zeros((diff,3))\n",
    "#         points = np.concatenate([points,padd],axis=0)\n",
    "#         colors = np.concatenate([colors,padd[:,0]],axis=0)\n",
    "#     return {'coordinates': points,'dose_values': colors}\n",
    "\n",
    "# def compile_pointclouds(patient,\n",
    "#                         batch_index=None, \n",
    "#                         organs = Const.organ_list + ['gtv','gtvn'],\n",
    "#                         downsample_k=1,\n",
    "#                         max_points=5000,\n",
    "#                         add_organ_key = False,\n",
    "#                        ):\n",
    "#     cpc = patient['contour_pointclouds']\n",
    "#     all_points = []\n",
    "#     all_values = []\n",
    "#     patient_max_dose = 0\n",
    "#     for organ in organs:\n",
    "#         entry = cpc.get(organ)\n",
    "#         if entry is None:\n",
    "#             continue\n",
    "#         coords = np.array(entry['coordinates'])\n",
    "#         values = np.array(entry['dose_values'])\n",
    "#         patient_max_dose = max(values.max(),patient_max_dose)\n",
    "#         all_points.append(coords)\n",
    "#         all_values.append(values)\n",
    "#     all_points = np.concatenate(all_points,axis=0)\n",
    "#     all_values = np.concatenate(all_values,axis=0).ravel()\n",
    "#     entry = {'coordinates': all_points,'dose_values':all_values}\n",
    "#     if downsample_k > 0:\n",
    "#         entry = downsample_pointcloud(entry,downsample_k,max_points)\n",
    "#     if batch_index is not None:\n",
    "#         ap = entry['coordinates']\n",
    "#         bi = np.full((ap.shape[0],1),batch_index)\n",
    "#         entry['coordinates'] =np.hstack((ap,bi))\n",
    "#     entry['patient_id'] = patient['patient_id']\n",
    "#     return entry\n",
    "\n",
    "# class SparseCNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self,dims=3,features=1,\n",
    "#                  output_dim = 1,\n",
    "#                  manifold_m = [32,32],\n",
    "#                  manifold_size=[3,3],\n",
    "#                  full_m = [32],\n",
    "#                  full_size = 5,\n",
    "#                  reps=1,\n",
    "#                 ):\n",
    "#         nn.Module.__init__(self)\n",
    "#         self.dims = dims\n",
    "#         self.features = features\n",
    "    \n",
    "#         self.input_layer = scn.InputLayer(dims,features) \n",
    "#         self.batchNorm = scn.BatchNormalization(features) # I don't actually know what input planes means\n",
    "#         self.manifold = scn.SubmanifoldConvolution(dims,features,manifold_m[0],manifold_size[0],True)\n",
    "#         self.manifold2 = scn.SubmanifoldConvolution(dims,manifold_m[0],manifold_m[1],manifold_size[1],True)\n",
    "\n",
    "#         self.batchNorm2 = scn.BatchNormReLU(manifold_m[-1])\n",
    "#         self.fullConv = scn.FullConvolution(dims,manifold_m[-1],full_m[0],full_size,1,True)\n",
    "        \n",
    "#         #with submanifold it will be last # of features, fullConvolution seems to be features*(full_size**3)\n",
    "#         self.final_dim = full_m[-1]*(full_size**3)\n",
    "#         self.sparseToDense = scn.SparseToDense(dims,full_m[-1])\n",
    "\n",
    "#         self.linear = nn.LazyLinear(output_dim)\n",
    "        \n",
    "#     def forward(self,locs,features,batch_size):\n",
    "#         x = self.input_layer((locs,features,batch_size))\n",
    "#         x = self.batchNorm(x)\n",
    "#         x = self.manifold(x)\n",
    "#         x = self.manifold2(x)\n",
    "    \n",
    "#         x = self.batchNorm2(x)\n",
    "#         x = self.fullConv(x)\n",
    "#         x = self.sparseToDense(x)\n",
    "#         x = x.view(x.shape[0],-1)\n",
    "#         x = self.linear(x)\n",
    "#         return x\n",
    "    \n",
    "# def SparseAutoEncoder(nn.Module):\n",
    "#     def __init__(self,dims=3,features=1,\n",
    "#                  output_dim = 1,\n",
    "#                  manifold_m = [32,32,32,32],\n",
    "#                  manifold_size=[3,3,3,3],\n",
    "#                  full_m = [32],\n",
    "#                  full_size = 5,\n",
    "#                  reps=1,\n",
    "#                 ):\n",
    "#         nn.Module.__init__(self)\n",
    "#         self.dims = dims\n",
    "#         self.features = features\n",
    "    \n",
    "#         self.input_layer = scn.InputLayer(dims,features) \n",
    "#         self.batchNorm = scn.BatchNormalization(features) # I don't actually know what input planes means\n",
    "#         self.manifold = scn.SubmanifoldConvolution(dims,features,manifold_m[0],manifold_size[0],True)\n",
    "#         self.manifold2 = scn.SubmanifoldConvolution(dims,manifold_m[0],manifold_m[1],manifold_size[1],True)\n",
    "\n",
    "#         self.batchNorm2 = scn.BatchNormReLU(manifold_m[-1])\n",
    "        \n",
    "#     def forward(self,locs,features,batch_size):\n",
    "#         x = self.input_layer((locs,features,batch_size))\n",
    "#         x = self.batchNorm(x)\n",
    "#         x = self.manifold(x)\n",
    "#         x = self.manifold2(x)\n",
    "    \n",
    "#         x = self.batchNorm2(x)\n",
    "#         x = self.fullConv(x)\n",
    "#         x = self.sparseToDense(x)\n",
    "# #         x = x.view(x.shape[0],-1)\n",
    "# #         x = self.linear(x)\n",
    "#         return x\n",
    "    \n",
    "# model = SparseCNN()\n",
    "# model = model.to(device)\n",
    "# model(test_l,test_f,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881e915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
